{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a character-level GPT on some text data\n",
    "\n",
    "The inputs here are simple text files, which we chop up to individual characters and then train GPT on. So you could say this is a char-transformer instead of a char-rnn. Doesn't quite roll off the tongue as well. In this example we will feed it some Shakespeare, which we'll get it to predict character-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128 # spatial extent of the model for its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 5893990 characters, 168 unique.\n"
     ]
    }
   ],
   "source": [
    "# you can download this file at https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt\n",
    "text = open('mega_poem.txt', 'r', encoding=\"utf-8\").read() # don't worry we won't run out of file handles\n",
    "train_dataset = CharDataset(text[:], block_size) # one line of poem is roughly 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/10/2021 07:01:17 - INFO - mingpt.model -   number of parameters: 2.545766e+07\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                  n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)\n",
    "torch.save(model.state_dict(), \"sample_model2.checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 184183: train loss 0.67322. lr 3.000032e-04: 100%|██████████| 184184/184184 [5:33:12<00:00,  9.21it/s]\n",
      "12/10/2021 12:34:32 - INFO - mingpt.trainer -   saving latest_model_12_10_21.ckpt\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=1, batch_size=32, learning_rate=6e-4,\n",
    "                      lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "                      num_workers=0, ckpt_path=\"latest_model_12_10_21.ckpt\")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem Start\n",
      "Irony\n",
      "\n",
      "\n",
      "Poem Start\n",
      "A Dream \n",
      "\n",
      "I am writing this poem.\n",
      "Poem Start\n",
      "Chicago Poem \n",
      "\n",
      "In the nine time you ceased throw out\n",
      "your hands, remember me.\n",
      "This child is me.\n",
      "Every moment she took my brain\n",
      "I crave to crawl through the wrongs\n",
      "on her lady's bed.\n",
      "that leaf draws the sorrow into her nights\n",
      "when in her mother's child grames they reach her gun.\n",
      "The days of she likep them in the dirt,\n",
      "And never the broken throng\n",
      "With the beautiful sea?\n",
      "END\n",
      "Lord Joe Peal Aliks\n",
      "\n",
      "\n",
      "Poem Start\n",
      "A Frog Octave \n",
      "\n",
      "A Frog can be a road on a homeless peach\n",
      "At night\n",
      "I have four dinner comes a tool\n",
      "A constant big old log in\n",
      "Behold their hands in my physical way\n",
      "I am like a lot of harms infested and big\n",
      "But never changing, my new sandals born\n",
      "The sun and my heat casts my head away\n",
      "And my mouth shanks and hurtles the day\n",
      "END\n",
      "Abdul Wahab\n",
      "\n",
      "\n",
      "Poem Start\n",
      "Peace \n",
      "\n",
      "After 15 decided to recieve\n",
      "In the Human World of today has gone\n",
      "And some what it does in my heartbeat.\n",
      "I see the sky in the dark\n",
      "Swimming in the crystal with tears\n",
      "And letting the cups\n",
      "Tickets fast green\n",
      "With the wishes\n",
      "The corpse crawl\n",
      "He was a crawl\n",
      "He was an order\n",
      "And an ordinary hug over woods\n",
      "With his fruit in the forest land\n",
      "In Heaven's dusk once the memory land\n",
      "From Hymna's sake he had drowned near all disprint,\n",
      "And he hears bush while the golden came brings,\n",
      "With heart heard about it in between,\n",
      "And dimly experience princess,\n",
      "And how he had come his tucking mind eyes\n",
      "To his hearthly power to the end.\n",
      "With gratitude in his issues\n",
      "Visit him by dreams and hearts.\n",
      "END\n",
      "Alfred Edward Housman\n",
      "\n",
      "\n",
      "Poem Start\n",
      "Sonnet Ciii \n",
      "\n",
      "What's not a friend, in masters devotion of men's strife?\n",
      "But 'tis not that encircarn about him that does seem to like this\n",
      " again, thus now I will fore, I will not believe that time come true! -\n",
      "\n",
      "The despite this that I am doing to do anything and everything that I do\n",
      "And to know that this thing I do about it will always be this time\n",
      "It would be right to free and to give me money\n",
      "It takes my life back to me\n",
      "It is really funny when money l\n"
     ]
    }
   ],
   "source": [
    "# alright, let's sample some character-level Shakespeare\n",
    "\n",
    "from mingpt.utils import sample\n",
    "trainer.load_checkpoint()\n",
    "context = \"Poem Start\\nIrony\\n\"\n",
    "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None,...].to(trainer.device)\n",
    "y = sample(model, x, 2000, temperature=1.0, sample=True, top_k=10)[0]\n",
    "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# well that was fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0addf8f22d8c836204ce3be080edc45558007cc167fa6a1e84d84279a5c463ed"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
